{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ssl\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!arch -arm64 brew install portaudio\n",
    "#!arch -arm64 brew link portaudio\n",
    "\n",
    "#!pip uninstall pyaudio --y\n",
    "\n",
    "#!pip3 install --no-cache-dir --global-option='build_ext' --global-option='-I/opt/homebrew/Cellar/portaudio/19.7.0/include' --global-option='-L/opt/homebrew/Cellar/portaudio/19.7.0/lib' pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def record_audio(time_seconds):\n",
    "\n",
    "    chunk = 1024  # Record in chunks of 1024 samples\n",
    "    sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "    channels = 1\n",
    "    fs = 48000  # Record at 44100 samples per second\n",
    "    filename = \"output.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "\n",
    "    seconds = time_seconds\n",
    "\n",
    "    print('Recording')\n",
    "\n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=fs,\n",
    "                    frames_per_buffer=chunk,\n",
    "                    input=True)\n",
    "\n",
    "    frames = []  # Initialize array to store frames\n",
    "\n",
    "    # Store data in chunks for 3 seconds\n",
    "    for i in range(0, int(fs / chunk * seconds)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    # Stop and close the stream \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    # Terminate the PortAudio interface\n",
    "    p.terminate()\n",
    "\n",
    "    print('Finished recording')\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "    wf.setframerate(fs)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "whisper_model = whisper.load_model(\"small.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# device = \"mps\" if  torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text(model,path):\n",
    "    result = model.transcribe(path)\n",
    "    print('voice processed')\n",
    "    return(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "def texttospeech(text_input):\n",
    "    pyobj = pyttsx3.init()\n",
    "    pyobj.setProperty('rate', 100) \n",
    "    pyobj.say(text_input)\n",
    "    pyobj.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "texttospeech(\"My name is bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "mname = \"facebook/blenderbot-400M-distill\"\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname)\n",
    "tokenizer = AutoTokenizer.from_pretrained(mname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(UTTERANCE):\n",
    "    print(\"Human: \", UTTERANCE)\n",
    "\n",
    "    inputs = tokenizer([UTTERANCE], return_tensors=\"pt\")\n",
    "    reply_ids = model.generate(**inputs)\n",
    "    reply = tokenizer.batch_decode(reply_ids, skip_special_tokens=True)[0]\n",
    "    print(\"Bot: \", reply )\n",
    "    return reply\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "Finished recording\n",
      "voice processed\n",
      "Human:   Hi, how are you doing?\n",
      "Bot:   I'm doing well, thank you. I hope you are as well. How are you?\n",
      "Recording\n",
      "Finished recording\n",
      "voice processed\n",
      "Human:   I am also great just chatting with a friend on Zoom.\n",
      "Bot:   That's cool. What do you like to do in your free time? I like to play video games.\n",
      "Recording\n",
      "Finished recording\n",
      "voice processed\n",
      "Human:   I'm not a video game enthusiast but I like playing chess.\n",
      "Bot:   Chess is a great game. It was developed by Richard Garfield in 1958.\n",
      "Recording\n",
      "Finished recording\n",
      "voice processed\n",
      "Human:   Wow, that's great to hear.\n",
      "Bot:   I know, I am so happy for her.  I hope she continues to do well.\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    record_audio(5)\n",
    "    UTTERANCE = audio_to_text(whisper_model,\"output.wav\")\n",
    "    reply = chat(UTTERANCE)\n",
    "    texttospeech(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "174b908828a95327d8a80a972e6010943b4d74829279f8ab86932c037d75785c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
